approx_num_layers,precision,per_device_train_batch_size,gradient_accumulation_steps,enable_gradient_checkpointing,optimizer,learning_rate,weight_decay,lr_scheduler_type,warmup_epochs,drop_path_rate,label_smoothing,gradient_clipping
30,bf16,16,1,False,AdamW,1e-4,0.01,cosine,5,0.1,0.1,1.0
50,bf16,8,2,True,AdamW,1e-4,0.01,cosine,5,0.1,0.1,1.0
70,bf16,4,4,True,AdamW,1e-4,1e-4,cosine,5,0.1,0.1,0.1
90,bf16,2,8,True,AdamW,1e-3,1e-4,cosine,5,0.1,0.1,0.1
