"""
Dataset utilities for ConvForever
"""

import os
import tempfile
import shutil
import json
import requests
from io import BytesIO
from PIL import Image
from torchvision import transforms
from torch.utils.data import Dataset, DataLoader
from datasets import load_dataset

from .model import CATEGORIES


def download_image_to_path(url, temp_dir):
    """Download an image from URL to a temporary path."""
    try:
        r = requests.get(url, timeout=10)
        r.raise_for_status()
        img = Image.open(BytesIO(r.content)).convert("RGB")
        path = os.path.join(temp_dir, "img.jpg")
        img.save(path)
        return path
    except Exception:
        return None


class JsonImageDataset(Dataset):
    """Dataset class for loading JSON records with image URLs and labels."""
    
    def __init__(self, records, transform=None):
        self.records = records
        self.transform = transform
        self.label_to_id = {cat: i for i, cat in enumerate(CATEGORIES)}
        
    def __len__(self):
        return len(self.records)
        
    def __getitem__(self, idx):
        rec = self.records[idx]
        temp_dir = tempfile.mkdtemp()
        img_path = download_image_to_path(rec["url"], temp_dir)
        if not img_path:
            shutil.rmtree(temp_dir)
            return self.__getitem__((idx + 1) % len(self))
        
        img = Image.open(img_path).convert("RGB")
        if self.transform:
            img = self.transform(img)
        shutil.rmtree(temp_dir, ignore_errors=True)
        
        label = rec["label"]
        # Handle both string labels (LAION format) and numeric labels
        if isinstance(label, str):
            label_id = self.label_to_id[label]
        else:
            label_id = label
            
        return img, label_id


class LaionImageNetDataset(Dataset):
    """Dataset class for LAION format ImageNet using HuggingFace datasets with JSON-style labels."""
    
    def __init__(self, split='train', transform=None, label_mapping_file=None):
        """
        Args:
            split: 'train', 'validation', or 'test'
            transform: torchvision transforms to apply to images
            label_mapping_file: Optional file to map ImageNet class IDs to our categories
        """
        # Load ImageNet-1K dataset from HuggingFace with streaming enabled
        self.dataset = load_dataset("ILSVRC/imagenet-1k", split=split, trust_remote_code=True, streaming=True)
        self.stream = iter(self.dataset)
        self.transform = transform
        
        # If we have a custom label mapping, use it
        if label_mapping_file and os.path.exists(label_mapping_file):
            with open(label_mapping_file, 'r') as f:
                self.label_mapping = json.load(f)
        else:
            # Create default mapping - this would map ImageNet synsets to our categories
            # For now, we'll just use the original ImageNet labels
            self.label_mapping = None
        
    def __len__(self):
        return len(self.dataset)
        
    def __getitem__(self, idx):
        item = self.dataset[idx]
        # Convert image to RGB if needed
        img = item['image'].convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        # Get label - handle both raw label and mapped label
        label = item['label']
        
        # If we have a label mapping, apply it
        if self.label_mapping:
            # This assumes the mapping converts from ImageNet ID to our category ID
            label = self.label_mapping.get(str(label), label)
        
        return img, label


def get_transforms():
    """Get standard image transformations for training."""
    return transforms.Compose([
        transforms.RandomResizedCrop(224, scale=(0.8, 1.0)),
        transforms.RandomHorizontalFlip(),
        transforms.ToTensor(),
        transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
    ])


class ImageNetDataset(Dataset):
    """Dataset class for ImageNet using HuggingFace datasets."""
    
    def __init__(self, split='train', transform=None):
        """
        Args:
            split: 'train', 'validation', or 'test'
            transform: torchvision transforms to apply to images
        """
        # Load ImageNet-1K dataset from HuggingFace with streaming enabled
        self.dataset = load_dataset("ILSVRC/imagenet-1k", split=split, trust_remote_code=True, streaming=True)
        self.transform = transform

    def __iter__(self):
        """Make the dataset iterable for streaming."""
        for item in self.dataset:
            # Convert image to RGB if needed
            img = item['image'].convert('RGB')
            
            if self.transform:
                img = self.transform(img)
            
            # Label is already in numeric form in ImageNet
            label = item['label']
            
            yield img, label

    def __len__(self):
        # Streaming datasets don't support len() operation
        # We can't determine the length without iterating through the whole dataset
        # So we'll raise an error to indicate this limitation
        raise NotImplementedError("Streaming datasets don't support __len__")
        
    def __getitem__(self, idx):
        # Streaming datasets don't support random access
        # This method is not compatible with streaming datasets
        raise NotImplementedError("Streaming datasets don't support random indexing (__getitem__) with an index. Use iteration instead.")


class PdExtendedDataset(Dataset):
    """Dataset class for PD Extended using HuggingFace datasets with pre-classified labels."""
    
    def __init__(self, split='train', transform=None, label_mapping_file=None):
        """
        Args:
            split: 'train', 'validation', or 'test'
            transform: torchvision transforms to apply to images
            label_mapping_file: Optional file to map PD Extended labels to our categories
        """
        # Load PD Extended dataset from HuggingFace
        self.dataset = load_dataset("Spawning/pd-extended", split=split, trust_remote_code=True)
        self.transform = transform
        
        # If we have a custom label mapping, use it
        if label_mapping_file and os.path.exists(label_mapping_file):
            with open(label_mapping_file, 'r') as f:
                self.label_mapping = json.load(f)
        else:
            # Create default mapping based on our categories
            self.label_mapping = {cat: i for i, cat in enumerate(CATEGORIES)}
        
    def __len__(self):
        return len(self.dataset)
        
    def __getitem__(self, idx):
        item = self.dataset[idx]
        # Convert image to RGB if needed
        img = item['image'].convert('RGB')
        
        if self.transform:
            img = self.transform(img)
        
        # Get label from the dataset - PD Extended may have string labels that need mapping
        original_label = item.get('label', item.get('category', 'unknown'))
        
        # Map the label to our category IDs
        if isinstance(original_label, str):
            # If it's already in our category format, map directly
            if original_label in self.label_mapping:
                label = self.label_mapping[original_label]
            else:
                # If it's not in our mapping, default to 0 or unknown category
                label = 0  # or could be self.label_mapping.get('unknown', 0)
        else:
            # If it's already a numeric label, use it directly
            label = original_label
        
        return img, label


def get_imagenet_dataloader(split='train', batch_size=32, shuffle=True, transform=None, num_workers=4):
    """
    Get a dataloader for ImageNet dataset.
    
    Args:
        split: 'train', 'validation', or 'test'
        batch_size: batch size for dataloader
        shuffle: whether to shuffle the data (Note: with streaming, this uses a buffer-based shuffle)
        transform: torchvision transforms to apply
        num_workers: number of worker processes for data loading
    """
    if transform is None:
        if split == 'train':
            transform = get_transforms()
        else:
            # Standard validation transforms (no augmentation)
            transform = transforms.Compose([
                transforms.Resize(256),
                transforms.CenterCrop(224),
                transforms.ToTensor(),
                transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
            ])
    
    dataset = ImageNetDataset(split=split, transform=transform)
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=False,  # For streaming datasets, we disable shuffle here
        num_workers=num_workers,
        pin_memory=True
    )
    
    return dataloader


def get_dataset_by_format(dataset_format='imagenet', split='train', batch_size=32, shuffle=True, transform=None, num_workers=4, **kwargs):
    """
    Get a dataloader for different dataset formats (ImageNet, LAION-style JSON, or PD Extended).
    
    Args:
        dataset_format: 'imagenet' for standard ImageNet format, 'json'/'laion' for LAION-style JSON format,
                       or 'pd_extended' for PD Extended format (streamed HuggingFace parquet with pre-classified labels)
        split: 'train', 'validation', or 'test' (for ImageNet/PD Extended) or path to JSON file (for JSON format)
        batch_size: batch size for dataloader
        shuffle: whether to shuffle the data
        transform: torchvision transforms to apply
        num_workers: number of worker processes for data loading
        **kwargs: additional arguments passed to dataset constructors
    """
    if dataset_format == 'imagenet':
        if transform is None:
            if split == 'train':
                transform = get_transforms()
            else:
                # Standard validation transforms (no augmentation)
                transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ])
        
        dataset = ImageNetDataset(split=split, transform=transform, **kwargs)
        shuffle = False  # Disable shuffling for streaming datasets
    elif dataset_format == 'laion' or dataset_format == 'json':
        # For JSON format, split parameter should be the path to the JSON file
        json_path = split
        with open(json_path, 'r') as f:
            records = json.load(f)
        
        if transform is None:
            if 'train' in json_path.lower():
                transform = get_transforms()
            else:
                # Standard validation transforms (no augmentation)
                transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ])
        
        dataset = JsonImageDataset(records=records, transform=transform)
    elif dataset_format == 'laion_imagenet':
        # Using the LAION format for ImageNet data (with possible label mapping)
        if transform is None:
            if split == 'train':
                transform = get_transforms()
            else:
                # Standard validation transforms (no augmentation)
                transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ])
        
        dataset = LaionImageNetDataset(split=split, transform=transform, **kwargs)
        shuffle = False  # Disable shuffling for streaming datasets
    elif dataset_format == 'pd_extended':
        # Using PD Extended format (streamed HuggingFace parquet with pre-classified labels)
        if transform is None:
            if split == 'train':
                transform = get_transforms()
            else:
                # Standard validation transforms (no augmentation)
                transform = transforms.Compose([
                    transforms.Resize(256),
                    transforms.CenterCrop(224),
                    transforms.ToTensor(),
                    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),
                ])
        
        dataset = PdExtendedDataset(split=split, transform=transform, **kwargs)
    else:
        raise ValueError(f"Unsupported dataset format: {dataset_format}")
    
    dataloader = DataLoader(
        dataset,
        batch_size=batch_size,
        shuffle=shuffle,
        num_workers=num_workers,
        pin_memory=True
    )
    
    return dataloader